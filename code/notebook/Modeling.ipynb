{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.ensemble                    import RandomForestClassifier\n",
    "from sklearn.linear_model                import LogisticRegression\n",
    "from sklearn.model_selection             import RandomizedSearchCV\n",
    "from sklearn.model_selection             import cross_validate\n",
    "\n",
    "from sklearn.model_selection             import train_test_split\n",
    "from sklearn.preprocessing               import OrdinalEncoder\n",
    "from sklearn.feature_extraction.text     import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text     import TfidfTransformer\n",
    "from sklearn.feature_extraction.text     import CountVectorizer\n",
    "from sklearn.pipeline                    import Pipeline\n",
    "from sklearn.compose                     import ColumnTransformer\n",
    "from sklearn.impute                      import SimpleImputer\n",
    "\n",
    "from sklearn.metrics                     import f1_score\n",
    "from sklearn.metrics                     import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"EWG_product.csv\"\n",
    "product_df = pd.read_csv(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droping duplicates \n",
    "product_df = product_df.drop_duplicates()\n",
    "\n",
    "# renaming columns \n",
    "product_df.columns = ['ingredient_score', 'data_availability', 'ingredient', 'ingredient_concerns', 'product_name', 'company', 'product_url', 'product_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = product_df['product_score'].copy()\n",
    "X = product_df.drop('product_score', axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean for Modeling  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Encode y (i.e. change verified to 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_y(raw_y): \n",
    "    \"\"\"converts y to numerical target by converting 'verified' to 0.\"\"\"\n",
    "    y_clean_list = []\n",
    "    for i in raw_y:\n",
    "        if 'verified' in i: \n",
    "            y_clean_list.append(0)\n",
    "        else:\n",
    "            y_clean_list.append(int(i))\n",
    "    return y_clean_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Clean X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(transformers=[('availability_encoder',\n",
       "                                                  Pipeline(steps=[('availability_encoder',\n",
       "                                                                   OrdinalEncoder(categories=[['None',\n",
       "                                                                                               'Limited',\n",
       "                                                                                               'Fair',\n",
       "                                                                                               'Good',\n",
       "                                                                                               'Robust']],\n",
       "                                                                                  handle_unknown='use_encoded_value',\n",
       "                                                                                  unknown_value=-1))]),\n",
       "                                                  ['data_availability']),\n",
       "                                                 ('company_encoder',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(fill_value='missing',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('company_encoder',\n",
       "                                                                   OrdinalEncoder(handle_unknown='use_encoded_value',\n",
       "                                                                                  unknown_value=-1))]),\n",
       "                                                  ['company'])]))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoding availability  \n",
    "availability_pipe = Pipeline([('availability_encoder', OrdinalEncoder(categories = [['None', 'Limited', 'Fair', 'Good', 'Robust']], handle_unknown = 'use_encoded_value', unknown_value = -1))])\n",
    "# encoding company\n",
    "company_pipe = Pipeline([('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                     ('company_encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))])\n",
    "\n",
    "# combining preprocessing steps into one \n",
    "preprocessing = ColumnTransformer([('availability_encoder', availability_pipe, ['data_availability']),\n",
    "                                   ('company_encoder', company_pipe, ['company'])])\n",
    "\n",
    "pipe = Pipeline([('preprocessing', preprocessing)])\n",
    "\n",
    "# fitting the ordinal encoders on the training data only \n",
    "pipe.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['encoded_availability', 'encoded_company'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-edf6f3d3b0ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# preprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0my_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mX_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-edf6f3d3b0ce>\u001b[0m in \u001b[0;36mclean_X\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;34m\"\"\"Takes in X predictor dataframe, returns cleaned X predictor dataframe\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoded_availability'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoded_company'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchange_ingredient_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2933\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2934\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2935\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2937\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_setitem_array\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2963\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2964\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2965\u001b[0;31m                 indexer = self.loc._get_listlike_indexer(\n\u001b[0m\u001b[1;32m   2966\u001b[0m                     \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2967\u001b[0m                 )[1]\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1550\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m         self._validate_read_indexer(\n\u001b[0m\u001b[1;32m   1553\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m         )\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1638\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1639\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1640\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1642\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['encoded_availability', 'encoded_company'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "def change_ingredient_score(X):\n",
    "    \"\"\"Takes median score for each ingredient and finds mean ingredient score for each product. \n",
    "    Returns dataframe.\"\"\"\n",
    "    # find median score per ingredient\n",
    "    X['median_ingredient_score'] = X.groupby(by='ingredient')['ingredient_score'].transform('median')\n",
    "    # calculate the mean of product scores for each product\n",
    "    X['mean_product_score'] = X.groupby(by=['product_name'])['median_ingredient_score'].transform('mean')\n",
    "    return X\n",
    "\n",
    "def clean_X(X):\n",
    "    \"\"\"Takes in X predictor dataframe, returns cleaned X predictor dataframe\"\"\"\n",
    "    X = X.copy()\n",
    "    X[['encoded_availability', 'encoded_company']] = pipe.transform(X)\n",
    "    X = change_ingredient_score(X)\n",
    "    return X\n",
    "\n",
    "# preprocessing \n",
    "y_train = clean_y(y_train)\n",
    "X_train = clean_X(X_train)\n",
    "y_valid = clean_y(y_valid)\n",
    "X_valid = clean_X(X_valid)\n",
    "y_test = clean_y(y_test)\n",
    "X_test = clean_X(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Model: Logistic Regression\n",
    "#### simplest version with mean product score as only predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lf = LogisticRegression().fit(pd.DataFrame(X_train['mean_product_score']), y_train)\n",
    "train_predictions = lf.predict(pd.DataFrame(X_train['mean_product_score']))\n",
    "training_f1 = f1_score(y_train, train_predictions, average='weighted')\n",
    "training_acc = accuracy_score(y_train, train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.31512412305879295, 0.35578377517713555)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_f1, training_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance on Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.23218642837163506, 0.25262655205348616)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_predictions = lf.predict(pd.DataFrame(X_valid['mean_product_score']))\n",
    "valid_f1 = f1_score(y_valid, valid_predictions, average='weighted')\n",
    "valid_acc = accuracy_score(y_valid, valid_predictions)\n",
    "valid_f1, valid_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try fewer y's: Three Categories \n",
    "#### might be the better choice for our personal score to be transparent about how our schools are less informed than those from EWG\n",
    "\n",
    "We can get a much better score if we reduce the number of categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def narrow_y_categories(input_y):\n",
    "    y_train_reduced = []\n",
    "    for y in input_y:\n",
    "        if y <= 2:\n",
    "            y_train_reduced.append(1) \n",
    "        elif y <=6:\n",
    "            y_train_reduced.append(2)\n",
    "        else: \n",
    "            y_train_reduced.append(3)\n",
    "    return y_train_reduced\n",
    "y_train = narrow_y_categories(y_train)\n",
    "y_valid = narrow_y_categories(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = LogisticRegression().fit(pd.DataFrame(X_train['mean_product_score']), y_train_reduced)\n",
    "train_predictions = lf.predict(pd.DataFrame(X_train['mean_product_score']))\n",
    "training_f1 = f1_score(y_train_reduced, train_predictions, average='weighted')\n",
    "training_acc = accuracy_score(y_train_reduced, train_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5694329495981436, 0.6946103017275694)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_f1, training_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "performance on test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5819118095176152, 0.7041547277936963)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_predictions = lf.predict(pd.DataFrame(X_valid['mean_product_score']))\n",
    "valid_f1 = f1_score(y_valid, valid_predictions, average='weighted')\n",
    "valid_acc = accuracy_score(y_valid, valid_predictions)\n",
    "valid_f1, valid_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
